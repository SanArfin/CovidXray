{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73b55794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_augmentation_without_masks_plus_filter.ipynb\n",
    "\n",
    "# input: \n",
    "# - \"..\\data\\processed\\resized_normalized_filtered_without_masks\"   (this is output from normalisation_filteration_without_masks.ipynb)\n",
    "# - ../data/processed/df_xray_processed_normed_enc_train.cvs        (this is output from train_test_split.ipynb)\n",
    "# - ../data/processed/df_xray_processed_normed_enc_test.csv         (this is output from train_test_split.ipynb)\n",
    "\n",
    "# Info of input iamges:\n",
    "# - images resized to 128 x 128, \n",
    "# - applied filters (Gaussian Blur, Clahe)\n",
    "# - with no masks\n",
    "# - images in folder: resized_normalized_filtered_without_masks\n",
    "\n",
    "# output:\n",
    "# -  augmented images in folder: data\\processed\\augmented_filtered_without_masks_resized\n",
    "# - ../data/processed/df_xray_train_norm_plus_augmented_filtered_without_masks_resized.csv \n",
    "# - ../data/processed/df_xray_test_norm_filtered_without_masks_resized.csv \n",
    "# - train_data_resized_filtered_without_masks.npz\n",
    "# - test_data_resized_filtered_without_masks.npz \n",
    "    \n",
    "\n",
    "# Augmented data is created in the folder data\\processed\\augmented_filtered_without_masks_resized for the minority classes: [\"COVID\", \"Viral Pneumonia\", \"Lung_Opacity\"].\n",
    "# Additionally a csv-file 'df_xray_train_norm_plus_augmented_filtered_without_masks_resized.csv' is created in which all the images belonging to the training set (incl. augmented)\n",
    "# are listed with labels and encoded labels.\n",
    "# Additionally a the train data and labels are saved as flattened numpy arrays: train_data_resized_filtered_without_masks.npz\n",
    "# The associated test data set is produced aswell and saved as a flattened numpy array: test_data_resized_filtered_without_masks.npz \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c7c3a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e9e5d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths \n",
    "base_path = r\"..\\\\data\\\\\"\n",
    "base_path_out = os.path.join(base_path, \"processed\")   # path to read input csv-file from\n",
    "\n",
    "output_path = os.path.join(base_path_out, \"augmented_filtered_without_masks_resized_filter\") # path to write the\n",
    "\n",
    "\n",
    "# Define classes which need augmentation: \n",
    "classes_aug = [\"COVID\", \"Viral Pneumonia\", \"Lung_Opacity\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f31f19",
   "metadata": {},
   "source": [
    "## create train data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cca32e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv with data frame which contains infos to preprocessed  and normalized images and labels and encoded labels\n",
    "df_train = pd.read_csv(os.path.join(base_path_out,\"df_xray_processed_normed_enc_train.csv\"), sep=',', index_col=0)\n",
    "\n",
    "# change folder name for imput images\n",
    "df_train['path'] = df_train['path'].apply(lambda x: x.replace('normalized_xrays', 'resized_normalized_filtered_without_masks')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c92c83e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell is the workaround, because the mixed up folder structure: no subfolders for 4 classes\n",
    "\n",
    "# use classname as prefix for the filename\n",
    "df_train['file'] = df_train['file'].apply(lambda x: x.split(\"-\")[0]+\"_\"+x)\n",
    "\n",
    "# delete subdolder for class in paths\n",
    "df_train['path'] = df_train['path'].apply(lambda x: os.sep.join(x.split(os.sep)[:-1]))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "061d9130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get infos which is the majority class\n",
    "counts = df_train['label'].value_counts()\n",
    "\n",
    "# assume that the normal class is the majority class\n",
    "\n",
    "max_num = counts['Normal']\n",
    "\n",
    "iteration_per_class = {}\n",
    "\n",
    "for class_name in classes_aug:\n",
    "    class_num = counts[class_name]\n",
    "\n",
    "    div_res = round(max_num/class_num,0)    # calculate how many augmentation iteration we need\n",
    "    iteration = div_res - 1                 # it needs one iteration less, because we add the unaugmented data\n",
    "    \n",
    "    iteration_per_class.update({class_name: iteration})\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ad25287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yvonne\\Documents\\DataScientist_2025_local\\project_code\\.venv-xray\\Lib\\site-packages\\albumentations\\core\\validation.py:87: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Define augmentation pipeline\n",
    "\n",
    "# define probabilities of applying the different augmentation methods\n",
    "prob_rotate = 0.5    # probaility of using rotation\n",
    "prob_shift = 0.5     # probaility of using shifting\n",
    "prob_pipeline = 1.0  # The entire pipeline has a 100% chance to be applied. We want every image to be changed\n",
    "\n",
    "\n",
    "# Define the augmentation pipeline\n",
    "augmentation_pipeline = A.Compose([\n",
    "    A.OneOf([\n",
    "        A.Rotate(limit=15, p=prob_rotate),                                                 # Rotate with a limit of Â±15 degrees\n",
    "        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0, rotate_limit=0, p=prob_shift)  # Translation (shifting)\n",
    "    ], p=prob_pipeline)\n",
    "\n",
    "], p=1.0,                    # probability of the entire pipeline to be applied\n",
    "#seed = 137,                  # added seed for reproducibility  \n",
    "save_applied_params=True)    # save applied transformation parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5aeb791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data_frame which is filled with the infos to the augmented iamges:\n",
    "df_train_augmented = pd.DataFrame(columns=df_train.columns)\n",
    "#df_train_augmented.columns\n",
    "\n",
    "\n",
    "# loop through rows of df_train\n",
    "for index, row in df_train.iterrows():\n",
    "    # only do augmentation if class is not 'Normal'\n",
    "    if row['label'] in classes_aug:\n",
    "\n",
    "        # define output path for augmented image\n",
    "        augmented_dir = os.path.join(output_path, row['label'])\n",
    "        os.makedirs(augmented_dir, exist_ok=True) \n",
    "\n",
    "\n",
    "        # how many iterations of augmentation do we need?\n",
    "        num_iter = iteration_per_class[row['label']]\n",
    "\n",
    "        file = os.path.join(row['path'], row['file'])\n",
    "        \n",
    "        iter = 1\n",
    "        # for each file in the data frame to as many augmentation, as needed for this class\n",
    "        \n",
    "        img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            while iter <= num_iter: \n",
    "                      \n",
    "                augmented = augmentation_pipeline(image=img)\n",
    "                augmented_img = augmented['image']\n",
    "                \n",
    "                # save used transformation to dict\n",
    "                #used_transformation.update({img_name:augmented['applied_transforms']})\n",
    "                        \n",
    "                # define name for augmented image\n",
    "                split_name, split_ending = row['file'].split('.') \n",
    "                img_name_aug = split_name + \"_ag\" + str(iter) + \".\" + split_ending\n",
    "\n",
    "                # save augmented image\n",
    "                save_path = os.path.join(augmented_dir, img_name_aug)\n",
    "                cv2.imwrite(save_path, augmented_img)\n",
    "\n",
    "                # build a new row for the new dataframe df_train_augmented:\n",
    "                new_row_label = row['label']\n",
    "                new_row_file = img_name_aug\n",
    "                new_row_label_enc = row['label_enc']\n",
    "                new_row_path = augmented_dir\n",
    "                \n",
    "                new_row = {'label': new_row_label, \n",
    "                        'file': new_row_file, \n",
    "                        'label_enc': new_row_label_enc, \n",
    "                        'path': new_row_path }\n",
    "\n",
    "                #df_train_augmented= df_train_augmented.append(new_row, ignore_index = True)\n",
    "                df_train_augmented = pd.concat([df_train_augmented,pd.DataFrame([new_row])], ignore_index = True, axis = 0)\n",
    "\n",
    "                iter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14e4035f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Viral Pneumonia    7532\n",
       "COVID              5786\n",
       "Lung_Opacity       4809\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_augmented['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c832aac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat df with non augmented and augmented data: \n",
    " \n",
    "df_train_combined = pd.concat([df_train, df_train_augmented], ignore_index = True, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4dc22c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Lung_Opacity       9618\n",
       "COVID              8679\n",
       "Viral Pneumonia    8608\n",
       "Normal             8154\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_combined['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7353a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "file",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label_enc",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "path",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "677f48a1-492f-4a4e-a90c-5113beb46cc7",
       "rows": [
        [
         "19581",
         "Lung_Opacity",
         "Lung_Opacity_Lung_Opacity-5774.png",
         "1",
         "..\\\\data\\\\processed\\resized_normalized_filtered_without_masks"
        ],
        [
         "6967",
         "Normal",
         "NORMAL_NORMAL-3352.png",
         "2",
         "..\\\\data\\\\processed\\resized_normalized_filtered_without_masks"
        ],
        [
         "12317",
         "Normal",
         "NORMAL_NORMAL-8702.png",
         "2",
         "..\\\\data\\\\processed\\resized_normalized_filtered_without_masks"
        ],
        [
         "21004",
         "Viral Pneumonia",
         "Viral Pneumonia_Viral Pneumonia-1185.png",
         "3",
         "..\\\\data\\\\processed\\resized_normalized_filtered_without_masks"
        ],
        [
         "14804",
         "Lung_Opacity",
         "Lung_Opacity_Lung_Opacity-997.png",
         "1",
         "..\\\\data\\\\processed\\resized_normalized_filtered_without_masks"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "      <th>label_enc</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19581</th>\n",
       "      <td>Lung_Opacity</td>\n",
       "      <td>Lung_Opacity_Lung_Opacity-5774.png</td>\n",
       "      <td>1</td>\n",
       "      <td>..\\\\data\\\\processed\\resized_normalized_filtere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6967</th>\n",
       "      <td>Normal</td>\n",
       "      <td>NORMAL_NORMAL-3352.png</td>\n",
       "      <td>2</td>\n",
       "      <td>..\\\\data\\\\processed\\resized_normalized_filtere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12317</th>\n",
       "      <td>Normal</td>\n",
       "      <td>NORMAL_NORMAL-8702.png</td>\n",
       "      <td>2</td>\n",
       "      <td>..\\\\data\\\\processed\\resized_normalized_filtere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21004</th>\n",
       "      <td>Viral Pneumonia</td>\n",
       "      <td>Viral Pneumonia_Viral Pneumonia-1185.png</td>\n",
       "      <td>3</td>\n",
       "      <td>..\\\\data\\\\processed\\resized_normalized_filtere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14804</th>\n",
       "      <td>Lung_Opacity</td>\n",
       "      <td>Lung_Opacity_Lung_Opacity-997.png</td>\n",
       "      <td>1</td>\n",
       "      <td>..\\\\data\\\\processed\\resized_normalized_filtere...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 label                                      file  label_enc  \\\n",
       "index                                                                         \n",
       "19581     Lung_Opacity        Lung_Opacity_Lung_Opacity-5774.png          1   \n",
       "6967            Normal                    NORMAL_NORMAL-3352.png          2   \n",
       "12317           Normal                    NORMAL_NORMAL-8702.png          2   \n",
       "21004  Viral Pneumonia  Viral Pneumonia_Viral Pneumonia-1185.png          3   \n",
       "14804     Lung_Opacity         Lung_Opacity_Lung_Opacity-997.png          1   \n",
       "\n",
       "                                                    path  \n",
       "index                                                     \n",
       "19581  ..\\\\data\\\\processed\\resized_normalized_filtere...  \n",
       "6967   ..\\\\data\\\\processed\\resized_normalized_filtere...  \n",
       "12317  ..\\\\data\\\\processed\\resized_normalized_filtere...  \n",
       "21004  ..\\\\data\\\\processed\\resized_normalized_filtere...  \n",
       "14804  ..\\\\data\\\\processed\\resized_normalized_filtere...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eaea6315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save Df with combined data to csv\n",
    "df_train.to_csv(os.path.join(base_path_out, 'df_xray_train_norm_plus_augmented_filtered_without_masks_resized.csv'), index_label='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "788f936c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading and processing train images: 100%|ââââââââââ| 35059/35059 [11:28<00:00, 50.89it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (35059, 16384)\n",
      "y_train shape: (35059,)\n",
      "Resized and flattened train images without masks have been saved!\n"
     ]
    }
   ],
   "source": [
    "# convert and save data to npz\n",
    "\n",
    "df_train_combined['image_path'] = df_train_combined.apply(lambda row: os.path.join(row['path'], row['file']), axis=1)\n",
    "\n",
    "image_data = []\n",
    "for path in tqdm(df_train_combined['image_path'], desc=\"Loading and processing train images\"):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    img_flattened = img.reshape(-1)  # Flatten image to 1D vector\n",
    "    if img_flattened is not None:\n",
    "        image_data.append(img_flattened)\n",
    "\n",
    "# Convert to NumPy array\n",
    "X_train = np.array(image_data, dtype=np.uint8)\n",
    "y_train = df_train_combined['label_enc'].to_numpy()\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "# Save the resized and flattened training data\n",
    "np.savez_compressed(os.path.join(base_path_out, 'train_data_resized_filtered_without_masks.npz'), X_train=X_train, y_train=y_train)\n",
    "print(\"Resized and flattened train images without masks have been saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614e1dc0",
   "metadata": {},
   "source": [
    "## create test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29510bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv with data frame which contains infos to preprocessed  and normalized images and labels and encoded labels\n",
    "df_test = pd.read_csv(os.path.join(base_path_out,\"df_xray_processed_normed_enc_test.csv\"), sep=',', index_col=0)\n",
    "\n",
    "# change folder name for imput images\n",
    "df_test['path'] = df_test['path'].apply(lambda x: x.replace('normalized_xrays', 'resized_normalized_filtered_without_masks')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f12dae97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell is the workaround, because the mixed up folder structure: no subfolders for 4 classes\n",
    "\n",
    "# use classname as prefix for the filename\n",
    "df_test['file'] = df_test['file'].apply(lambda x: x.split(\"-\")[0]+\"_\"+x)\n",
    "\n",
    "# delete subdolder for class in paths\n",
    "df_test['path'] = df_test['path'].apply(lambda x: os.sep.join(x.split(os.sep)[:-1]))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27293fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save Df with test data to csv\n",
    "df_test.to_csv(os.path.join(base_path_out, 'df_xray_test_norm_filtered_without_masks_resized.csv'), index_label='index')\n",
    "                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6847538",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading and processing test images:   0%|          | 0/4233 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m tqdm(df_test[\u001b[33m'\u001b[39m\u001b[33mimage_path\u001b[39m\u001b[33m'\u001b[39m], desc=\u001b[33m\"\u001b[39m\u001b[33mLoading and processing test images\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m      7\u001b[39m     img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     img_flattened = \u001b[43mimg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreshape\u001b[49m(-\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# Flatten image to 1D vector\u001b[39;00m\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m img_flattened \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     10\u001b[39m         image_data.append(img_flattened)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "# convert and save data to npz\n",
    "\n",
    "df_test['image_path'] = df_test.apply(lambda row: os.path.join(row['path'], row['file']), axis=1)\n",
    "\n",
    "image_data = []\n",
    "for path in tqdm(df_test['image_path'], desc=\"Loading and processing test images\"):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    img_flattened = img.reshape(-1)  # Flatten image to 1D vector\n",
    "    if img_flattened is not None:\n",
    "        image_data.append(img_flattened)\n",
    "\n",
    "# Convert to NumPy array\n",
    "X_test = np.array(image_data, dtype=np.uint8)\n",
    "y_test = df_test['label_enc'].to_numpy()\n",
    "\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "# Save the resized and flattened test data\n",
    "np.savez_compressed(os.path.join(base_path_out, 'test_data_resized_filtered_without_masks.npz'), X_test=X_test, y_test=y_test)\n",
    "print(\"Resized and flattened test images without masks have been saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651f7b46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
