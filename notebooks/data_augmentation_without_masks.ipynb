{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c7c3a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yvonne\\Documents\\DataScientist_2025_local\\project_code\\.venv-xray\\Lib\\site-packages\\albumentations\\__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.6' (you have '2.0.5'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e9e5d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths \n",
    "base_path = r\"..\\\\data\\\\\"\n",
    "base_path_out = os.path.join(base_path, \"processed\")   # path to read input csv-file from\n",
    "\n",
    "output_path = os.path.join(base_path_out, \"augmented_without_masks_resized\") # path to write the\n",
    "\n",
    "\n",
    "# Define classes which need augmentation: \n",
    "classes_aug = [\"COVID\", \"Viral Pneumonia\", \"Lung_Opacity\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f31f19",
   "metadata": {},
   "source": [
    "## create train data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cca32e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv with data frame which contains infos to preprocessed  and normalized images and labels and encoded labels\n",
    "df_train = pd.read_csv(os.path.join(base_path_out,\"df_xray_processed_normed_enc_train.csv\"), sep=',', index_col=0)\n",
    "\n",
    "# change folder name for imput images\n",
    "df_train['path'] = df_train['path'].apply(lambda x: x.replace('normalized_xrays', 'resized_and_normalized_images_without_masks')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c92c83e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell is the workaround, because the mixed up folder structure: no subfolders for 4 classes\n",
    "\n",
    "# use classname as prefix for the filename\n",
    "df_train['file'] = df_train['file'].apply(lambda x: x.split(\"-\")[0]+\"_\"+x)\n",
    "\n",
    "# delete subdolder for class in paths\n",
    "df_train['path'] = df_train['path'].apply(lambda x: os.sep.join(x.split(os.sep)[:-1]))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "061d9130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get infos which is the majority class\n",
    "counts = df_train['label'].value_counts()\n",
    "\n",
    "# assume that the normal class is the majority class\n",
    "\n",
    "max_num = counts['Normal']\n",
    "\n",
    "iteration_per_class = {}\n",
    "\n",
    "for class_name in classes_aug:\n",
    "    class_num = counts[class_name]\n",
    "\n",
    "    div_res = round(max_num/class_num,0)    # calculate how many augmentation iteration we need\n",
    "    iteration = div_res - 1                 # it needs one iteration less, because we add the unaugmented data\n",
    "    \n",
    "    iteration_per_class.update({class_name: iteration})\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ad25287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yvonne\\Documents\\DataScientist_2025_local\\project_code\\.venv-xray\\Lib\\site-packages\\albumentations\\core\\validation.py:87: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Define augmentation pipeline\n",
    "\n",
    "# define probabilities of applying the different augmentation methods\n",
    "prob_rotate = 0.5    # probaility of using rotation\n",
    "prob_shift = 0.5     # probaility of using shifting\n",
    "prob_pipeline = 1.0  # The entire pipeline has a 100% chance to be applied. We want every image to be changed\n",
    "\n",
    "\n",
    "# Define the augmentation pipeline\n",
    "augmentation_pipeline = A.Compose([\n",
    "    A.OneOf([\n",
    "        A.Rotate(limit=15, p=prob_rotate),                                                 # Rotate with a limit of Â±15 degrees\n",
    "        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0, rotate_limit=0, p=prob_shift)  # Translation (shifting)\n",
    "    ], p=prob_pipeline)\n",
    "\n",
    "], p=1.0,                    # probability of the entire pipeline to be applied\n",
    "#seed = 137,                  # added seed for reproducibility  \n",
    "save_applied_params=True)    # save applied transformation parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5aeb791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data_frame which is filled with the infos to the augmented iamges:\n",
    "df_train_augmented = pd.DataFrame(columns=df_train.columns)\n",
    "#df_train_augmented.columns\n",
    "\n",
    "\n",
    "# loop through rows of df_train\n",
    "for index, row in df_train.iterrows():\n",
    "    # only do augmentation if class is not 'Normal'\n",
    "    if row['label'] in classes_aug:\n",
    "\n",
    "        # define output path for augmented image\n",
    "        augmented_dir = os.path.join(output_path, row['label'])\n",
    "        os.makedirs(augmented_dir, exist_ok=True) \n",
    "\n",
    "\n",
    "        # how many iterations of augmentation do we need?\n",
    "        num_iter = iteration_per_class[row['label']]\n",
    "\n",
    "        file = os.path.join(row['path'], row['file'])\n",
    "        \n",
    "        iter = 1\n",
    "        # for each file in the data frame to as many augmentation, as needed for this class\n",
    "        \n",
    "        img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            while iter <= num_iter: \n",
    "                      \n",
    "                augmented = augmentation_pipeline(image=img)\n",
    "                augmented_img = augmented['image']\n",
    "                \n",
    "                # save used transformation to dict\n",
    "                #used_transformation.update({img_name:augmented['applied_transforms']})\n",
    "                        \n",
    "                # define name for augmented image\n",
    "                split_name, split_ending = row['file'].split('.') \n",
    "                img_name_aug = split_name + \"_ag\" + str(iter) + \".\" + split_ending\n",
    "\n",
    "                # save augmented image\n",
    "                save_path = os.path.join(augmented_dir, img_name_aug)\n",
    "                cv2.imwrite(save_path, augmented_img)\n",
    "\n",
    "                # build a new row for the new dataframe df_train_augmented:\n",
    "                new_row_label = row['label']\n",
    "                new_row_file = img_name_aug\n",
    "                new_row_label_enc = row['label_enc']\n",
    "                new_row_path = augmented_dir\n",
    "                \n",
    "                new_row = {'label': new_row_label, \n",
    "                        'file': new_row_file, \n",
    "                        'label_enc': new_row_label_enc, \n",
    "                        'path': new_row_path }\n",
    "\n",
    "                #df_train_augmented= df_train_augmented.append(new_row, ignore_index = True)\n",
    "                df_train_augmented = pd.concat([df_train_augmented,pd.DataFrame([new_row])], ignore_index = True, axis = 0)\n",
    "\n",
    "                iter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14e4035f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Viral Pneumonia    7532\n",
       "COVID              5786\n",
       "Lung_Opacity       4809\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_augmented['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c832aac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat df with non augmented and augmented data: \n",
    " \n",
    "df_train_combined = pd.concat([df_train, df_train_augmented], ignore_index = True, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dc22c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Lung_Opacity       9618\n",
       "COVID              8679\n",
       "Viral Pneumonia    8608\n",
       "Normal             8154\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_combined['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7353a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "file",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label_enc",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "path",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "1ad31031-90d6-4aa8-8383-9bb6c06827dc",
       "rows": [
        [
         "19581",
         "Lung_Opacity",
         "Lung_Opacity_Lung_Opacity-5774.png",
         "1",
         "..\\\\data\\\\processed\\resized_and_normalized_images_without_masks"
        ],
        [
         "6967",
         "Normal",
         "NORMAL_NORMAL-3352.png",
         "2",
         "..\\\\data\\\\processed\\resized_and_normalized_images_without_masks"
        ],
        [
         "12317",
         "Normal",
         "NORMAL_NORMAL-8702.png",
         "2",
         "..\\\\data\\\\processed\\resized_and_normalized_images_without_masks"
        ],
        [
         "21004",
         "Viral Pneumonia",
         "Viral Pneumonia_Viral Pneumonia-1185.png",
         "3",
         "..\\\\data\\\\processed\\resized_and_normalized_images_without_masks"
        ],
        [
         "14804",
         "Lung_Opacity",
         "Lung_Opacity_Lung_Opacity-997.png",
         "1",
         "..\\\\data\\\\processed\\resized_and_normalized_images_without_masks"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "      <th>label_enc</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19581</th>\n",
       "      <td>Lung_Opacity</td>\n",
       "      <td>Lung_Opacity_Lung_Opacity-5774.png</td>\n",
       "      <td>1</td>\n",
       "      <td>..\\\\data\\\\processed\\resized_and_normalized_ima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6967</th>\n",
       "      <td>Normal</td>\n",
       "      <td>NORMAL_NORMAL-3352.png</td>\n",
       "      <td>2</td>\n",
       "      <td>..\\\\data\\\\processed\\resized_and_normalized_ima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12317</th>\n",
       "      <td>Normal</td>\n",
       "      <td>NORMAL_NORMAL-8702.png</td>\n",
       "      <td>2</td>\n",
       "      <td>..\\\\data\\\\processed\\resized_and_normalized_ima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21004</th>\n",
       "      <td>Viral Pneumonia</td>\n",
       "      <td>Viral Pneumonia_Viral Pneumonia-1185.png</td>\n",
       "      <td>3</td>\n",
       "      <td>..\\\\data\\\\processed\\resized_and_normalized_ima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14804</th>\n",
       "      <td>Lung_Opacity</td>\n",
       "      <td>Lung_Opacity_Lung_Opacity-997.png</td>\n",
       "      <td>1</td>\n",
       "      <td>..\\\\data\\\\processed\\resized_and_normalized_ima...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 label                                      file  label_enc  \\\n",
       "index                                                                         \n",
       "19581     Lung_Opacity        Lung_Opacity_Lung_Opacity-5774.png          1   \n",
       "6967            Normal                    NORMAL_NORMAL-3352.png          2   \n",
       "12317           Normal                    NORMAL_NORMAL-8702.png          2   \n",
       "21004  Viral Pneumonia  Viral Pneumonia_Viral Pneumonia-1185.png          3   \n",
       "14804     Lung_Opacity         Lung_Opacity_Lung_Opacity-997.png          1   \n",
       "\n",
       "                                                    path  \n",
       "index                                                     \n",
       "19581  ..\\\\data\\\\processed\\resized_and_normalized_ima...  \n",
       "6967   ..\\\\data\\\\processed\\resized_and_normalized_ima...  \n",
       "12317  ..\\\\data\\\\processed\\resized_and_normalized_ima...  \n",
       "21004  ..\\\\data\\\\processed\\resized_and_normalized_ima...  \n",
       "14804  ..\\\\data\\\\processed\\resized_and_normalized_ima...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eaea6315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save Df with combined data to csv\n",
    "df_train.to_csv(os.path.join(base_path_out, 'df_xray_train_norm_plus_augmented_without_masks_resized.csv'), index_label='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "788f936c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading and processing train images: 100%|ââââââââââ| 35059/35059 [07:16<00:00, 80.25it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (35059, 400)\n",
      "y_train shape: (35059,)\n",
      "Resized and flattened train images without masks have been saved!\n"
     ]
    }
   ],
   "source": [
    "# convert and save data to npz\n",
    "\n",
    "df_train_combined['image_path'] = df_train_combined.apply(lambda row: os.path.join(row['path'], row['file']), axis=1)\n",
    "\n",
    "image_data = []\n",
    "for path in tqdm(df_train_combined['image_path'], desc=\"Loading and processing train images\"):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    img_flattened = img.reshape(-1)  # Flatten image to 1D vector\n",
    "    if img_flattened is not None:\n",
    "        image_data.append(img_flattened)\n",
    "\n",
    "# Convert to NumPy array\n",
    "X_train = np.array(image_data, dtype=np.uint8)\n",
    "y_train = df_train_combined['label_enc'].to_numpy()\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "# Save the resized and flattened training data\n",
    "np.savez_compressed(os.path.join(base_path_out, 'train_data_resized_without_masks.npz'), X_train=X_train, y_train=y_train)\n",
    "print(\"Resized and flattened train images without masks have been saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614e1dc0",
   "metadata": {},
   "source": [
    "## create test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29510bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv with data frame which contains infos to preprocessed  and normalized images and labels and encoded labels\n",
    "df_test = pd.read_csv(os.path.join(base_path_out,\"df_xray_processed_normed_enc_test.csv\"), sep=',', index_col=0)\n",
    "\n",
    "# change folder name for imput images\n",
    "df_test['path'] = df_test['path'].apply(lambda x: x.replace('normalized_xrays', 'resized_and_normalized_images_without_masks')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f12dae97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell is the workaround, because the mixed up folder structure: no subfolders for 4 classes\n",
    "\n",
    "# use classname as prefix for the filename\n",
    "df_test['file'] = df_test['file'].apply(lambda x: x.split(\"-\")[0]+\"_\"+x)\n",
    "\n",
    "# delete subdolder for class in paths\n",
    "df_test['path'] = df_test['path'].apply(lambda x: os.sep.join(x.split(os.sep)[:-1]))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27293fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save Df with test data to csv\n",
    "df_test.to_csv(os.path.join(base_path_out, 'df_xray_test_norm_without_masks_resized.csv'), index_label='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6847538",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading and processing test images: 100%|ââââââââââ| 4233/4233 [01:24<00:00, 50.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (4233, 400)\n",
      "y_test shape: (4233,)\n",
      "Resized and flattened test images without masks have been saved!\n"
     ]
    }
   ],
   "source": [
    "# convert and save data to npz\n",
    "\n",
    "df_test['image_path'] = df_test.apply(lambda row: os.path.join(row['path'], row['file']), axis=1)\n",
    "\n",
    "image_data = []\n",
    "for path in tqdm(df_test['image_path'], desc=\"Loading and processing test images\"):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    img_flattened = img.reshape(-1)  # Flatten image to 1D vector\n",
    "    if img_flattened is not None:\n",
    "        image_data.append(img_flattened)\n",
    "\n",
    "# Convert to NumPy array\n",
    "X_test = np.array(image_data, dtype=np.uint8)\n",
    "y_test = df_test['label_enc'].to_numpy()\n",
    "\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "# Save the resized and flattened test data\n",
    "np.savez_compressed(os.path.join(base_path_out, 'test_data_resized_without_masks.npz'), X_test=X_test, y_test=y_test)\n",
    "print(\"Resized and flattened test images without masks have been saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651f7b46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
