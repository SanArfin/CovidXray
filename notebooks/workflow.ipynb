{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ca7a35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COVID X-ray Classification Project Workflow (ML + DL)\n",
    "\n",
    "# 1. Load & Preprocess Data\n",
    "# ---------------------------------------------------\n",
    "# - Load X-ray images and labels\n",
    "# - Resize to fixed shape (e.g., 299x299)\n",
    "# - Apply CLAHE, subtract mask\n",
    "# - Normalize pixel values (0-1)\n",
    "# - Convert to numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5b121c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "file",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "min_pixel",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "max_pixel",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mean_pixel",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "std_pixel",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "blank_image",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "c2eb6c0b-3d7c-4c3b-b9ae-66bebd3033e6",
       "rows": [
        [
         "0",
         "COVID",
         "COVID-1.png",
         "0",
         "255",
         "145.89684679142292",
         "51.81663222717359",
         "False"
        ],
        [
         "1",
         "COVID",
         "COVID-2.png",
         "32",
         "238",
         "150.6405297479894",
         "48.86769801070843",
         "False"
        ],
        [
         "2",
         "COVID",
         "COVID-3.png",
         "0",
         "255",
         "140.59861746512902",
         "50.20067945662855",
         "False"
        ],
        [
         "3",
         "COVID",
         "COVID-4.png",
         "1",
         "255",
         "116.71467880672476",
         "57.71977282621545",
         "False"
        ],
        [
         "4",
         "COVID",
         "COVID-5.png",
         "34",
         "246",
         "167.83579602017875",
         "48.4134121352346",
         "False"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "      <th>min_pixel</th>\n",
       "      <th>max_pixel</th>\n",
       "      <th>mean_pixel</th>\n",
       "      <th>std_pixel</th>\n",
       "      <th>blank_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COVID</td>\n",
       "      <td>COVID-1.png</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>145.896847</td>\n",
       "      <td>51.816632</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COVID</td>\n",
       "      <td>COVID-2.png</td>\n",
       "      <td>32</td>\n",
       "      <td>238</td>\n",
       "      <td>150.640530</td>\n",
       "      <td>48.867698</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COVID</td>\n",
       "      <td>COVID-3.png</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>140.598617</td>\n",
       "      <td>50.200679</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COVID</td>\n",
       "      <td>COVID-4.png</td>\n",
       "      <td>1</td>\n",
       "      <td>255</td>\n",
       "      <td>116.714679</td>\n",
       "      <td>57.719773</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COVID</td>\n",
       "      <td>COVID-5.png</td>\n",
       "      <td>34</td>\n",
       "      <td>246</td>\n",
       "      <td>167.835796</td>\n",
       "      <td>48.413412</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label         file  min_pixel  max_pixel  mean_pixel  std_pixel  \\\n",
       "0  COVID  COVID-1.png          0        255  145.896847  51.816632   \n",
       "1  COVID  COVID-2.png         32        238  150.640530  48.867698   \n",
       "2  COVID  COVID-3.png          0        255  140.598617  50.200679   \n",
       "3  COVID  COVID-4.png          1        255  116.714679  57.719773   \n",
       "4  COVID  COVID-5.png         34        246  167.835796  48.413412   \n",
       "\n",
       "   blank_image  \n",
       "0        False  \n",
       "1        False  \n",
       "2        False  \n",
       "3        False  \n",
       "4        False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 21165 entries, 0 to 21164\n",
      "Series name: label\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "21165 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 165.5+ KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. Encode Labels\n",
    "\n",
    "# input for this cell:    ../data/processed/image_stats_summary.csv        (must exist before running this cell)\n",
    "# output of this cell is: ../data/processed/image_stats_summary_enc.csv    (is created when running this cell)\n",
    "\n",
    "%run encode.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dec7568d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yvonne\\AppData\\Local\\Temp\\ipykernel_24856\\2367129792.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_processed['path'] = df_processed['label'].apply(lambda x: os.path.join(dir_processed_xray, x))\n"
     ]
    }
   ],
   "source": [
    "# 3. build data frame for further work(Imgages Normalised WIth masks)\n",
    "\n",
    "# input for this cell:    ../data/processed/image_stats_summary_enc.csv               (must exist before running this cell)\n",
    "# output of this cell is: ../data/processed/df_xray_processed_normed_enc.cvs          (is created when running this cell)\n",
    "\n",
    "# the resulting dataframe contains infos (path, filename) to the processed and normalized data and labels and encoded labels. \n",
    "# The following processing has been done to the images referred to in this dataframe:\n",
    "# - convert images and masks to grayscale\n",
    "# - resize masks\n",
    "# - convert masks to binary images                                                  # stored as convertd_grayscale\n",
    "# - apply Gaussian Blur to images\n",
    "# - apply Clahe to images    \n",
    "# - add masks to previously changed images (grayscale, Gaussian Blur, Clahe)        #stored as processed_xray\n",
    "# - normalize images                                                                #stored as normalized_xrays\n",
    "\n",
    "# It refers to the images which have been previously stored in the folder ..\\data\\processed\\normalized_xrays\n",
    "\n",
    "%run create_dataframe.ipynb\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c442240b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21165/21165 [01:14<00:00, 283.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resized and Normalized images loaded: (21165, 20, 20)\n",
      "Labels: ['COVID' 'Lung' 'Normal' 'Viral Pneumonia']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# build data frame for further work(Imgages Normalised WIthout masks)\n",
    "\n",
    "# input for this cell:    ../data/processed/converted_grayscale\n",
    "## output of this cell:     ../data/processed/resized_and_normalized_grayscale_without masks\n",
    "\n",
    "#images resized to (128* 128) suitable for ML namely random forest ,XG boost\n",
    "#no need to filters as we are anyhow resizing\n",
    "\n",
    "%run normalisation_image_without_masks.ipynb\n",
    "\n",
    "#next steps:encode,split, augment and flatten and tehn feed to ML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5aa303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "Normal             0.481550\n",
      "Lung_Opacity       0.284054\n",
      "COVID              0.170848\n",
      "Viral Pneumonia    0.063548\n",
      "Name: proportion, dtype: float64\n",
      "label_enc\n",
      "2    0.481550\n",
      "1    0.284054\n",
      "0    0.170848\n",
      "3    0.063548\n",
      "Name: proportion, dtype: float64\n",
      "processed data size:  21165\n",
      "train data size:  16932\n",
      "test data size:  4233\n",
      "----------------------------------------\n",
      "distribution of labels for train set:\n",
      "label_enc\n",
      "2    0.481573\n",
      "1    0.284018\n",
      "0    0.170860\n",
      "3    0.063548\n",
      "Name: proportion, dtype: float64\n",
      "----------------------------------------\n",
      "distribution of labels for test set:\n",
      "label_enc\n",
      "2    0.481455\n",
      "1    0.284196\n",
      "0    0.170801\n",
      "3    0.063548\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 4. Train-Test Split\n",
    "\n",
    "# input for this cell:    ../data/processed/df_xray_processed_normed_enc.cvs         (must exist before running this cell)\n",
    "# output of this cell is: ../data/processed/df_xray_processed_normed_enc_test.cvs    (is created when running this cell)\n",
    "#                         ../data/processed/df_xray_processed_normed_enc_train.cvs    (is created when running this cell)\n",
    "\n",
    "# This cell splits the DataFrame which contains infos to preprocessed and normalized images and labels and encoded labels into test and train.\n",
    "# No sepeartion of the columns with labels (target) is done here. \n",
    "# We have to sepearate the target variable later, bacause we need it in the following parts for data augmentation\n",
    "\n",
    "%run train_test_split.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106cf192",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yvonne\\Documents\\DataScientist_2025_local\\project_code\\.venv-xray\\Lib\\site-packages\\albumentations\\core\\validation.py:87: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n"
     ]
    }
   ],
   "source": [
    "# 5a) Class Imbalance Fix (only on training data) - [uses images from folder \\data\\processed\\normalized_xrays: images + masks, filter Clahe, Gaussian Blur, Normalization, 299x299 pixel)\n",
    "\n",
    "# input for this cell:    ../data/processed/df_xray_processed_normed_enc_train.cvs         (must exist before running this cell)\n",
    "# output of this cell is: ../data/processed/df_xray_train_norm_plus_augmented.csv          (is created when running this cell)\n",
    "\n",
    "\n",
    "# Augmented data is created in the folder data\\processed\\augmented for the minority classes: [\"COVID\", \"Viral Pneumonia\", \"Lung_Opacity\"].\n",
    "# Additionally a csv-file 'df_xray_train_norm_plus_augmented.csv' is created in which all the images belonging to the training set (incl. augmented)\n",
    "# are listed with labels and encoded labels\n",
    "\n",
    "\n",
    "%run data_augmentation.ipynb\n",
    "\n",
    "\n",
    "# you can use the follwing notebook optional to display examples of the processed & normalized images and augmented versions\n",
    "# data_augmentation_viz.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9729ea7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yvonne\\Documents\\DataScientist_2025_local\\project_code\\.venv-xray\\Lib\\site-packages\\albumentations\\__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.6' (you have '2.0.5'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "c:\\Users\\Yvonne\\Documents\\DataScientist_2025_local\\project_code\\.venv-xray\\Lib\\site-packages\\albumentations\\core\\validation.py:87: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_14224\\3697812363.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf_test\u001b[49m.tail()\n",
      "\u001b[31mNameError\u001b[39m: name 'df_test' is not defined"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 5b) Class Imbalance Fix (only on training data) - [uses images from folder \\data\\processed\\resized_and_normalized_grayscale_without masks: images, Normalization, 128x128 pixel]  ??? Shouldn't we use filtered versions (Gaussian Blur and Clahe) here too???\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# input: \u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Additionally a the train data and labels are saved as flattened numpy arrays: train_data_resized_without_masks.npz\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# The associated test data set is produced aswell and saved as a flattened numpy array: test_data_resized_without_masks.npz\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrun\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata_augmentation_without_masks.ipynb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# P.S.: I could not reuse data_augmentation.ipynb because the input folders have different structures\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yvonne\\Documents\\DataScientist_2025_local\\project_code\\.venv-xray\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2486\u001b[39m, in \u001b[36mInteractiveShell.run_line_magic\u001b[39m\u001b[34m(self, magic_name, line, _stack_depth)\u001b[39m\n\u001b[32m   2484\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mlocal_ns\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28mself\u001b[39m.get_local_scope(stack_depth)\n\u001b[32m   2485\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m-> \u001b[39m\u001b[32m2486\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2488\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2489\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2490\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2491\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yvonne\\Documents\\DataScientist_2025_local\\project_code\\.venv-xray\\Lib\\site-packages\\IPython\\core\\magics\\execution.py:748\u001b[39m, in \u001b[36mExecutionMagics.run\u001b[39m\u001b[34m(self, parameter_s, runner, file_finder)\u001b[39m\n\u001b[32m    746\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m preserve_keys(\u001b[38;5;28mself\u001b[39m.shell.user_ns, \u001b[33m'\u001b[39m\u001b[33m__file__\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    747\u001b[39m         \u001b[38;5;28mself\u001b[39m.shell.user_ns[\u001b[33m'\u001b[39m\u001b[33m__file__\u001b[39m\u001b[33m'\u001b[39m] = filename\n\u001b[32m--> \u001b[39m\u001b[32m748\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshell\u001b[49m\u001b[43m.\u001b[49m\u001b[43msafe_execfile_ipy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_exceptions\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    751\u001b[39m \u001b[38;5;66;03m# Control the response to exit() calls made by the script being run\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yvonne\\Documents\\DataScientist_2025_local\\project_code\\.venv-xray\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2977\u001b[39m, in \u001b[36mInteractiveShell.safe_execfile_ipy\u001b[39m\u001b[34m(self, fname, shell_futures, raise_exceptions)\u001b[39m\n\u001b[32m   2975\u001b[39m result = \u001b[38;5;28mself\u001b[39m.run_cell(cell, silent=\u001b[38;5;28;01mTrue\u001b[39;00m, shell_futures=shell_futures)\n\u001b[32m   2976\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m raise_exceptions:\n\u001b[32m-> \u001b[39m\u001b[32m2977\u001b[39m     \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2978\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result.success:\n\u001b[32m   2979\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Yvonne\\Documents\\DataScientist_2025_local\\project_code\\.venv-xray\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:310\u001b[39m, in \u001b[36mExecutionResult.raise_error\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    308\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m.error_before_exec\n\u001b[32m    309\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.error_in_exec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m.error_in_exec\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_14224\\3697812363.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf_test\u001b[49m.tail()\n",
      "\u001b[31mNameError\u001b[39m: name 'df_test' is not defined"
     ]
    }
   ],
   "source": [
    "# 5b) Class Imbalance Fix (only on training data) - [uses images from folder \\data\\processed\\resized_and_normalized_grayscale_without masks: images, Normalization, 128x128 pixel]  ??? Shouldn't we use filtered versions (Gaussian Blur and Clahe) here too???\n",
    "\n",
    "# input: \n",
    "# - \"..\\data\\processed\\resized_and_normalized_images_without_masks\" (this is output from normalisation_image_without_masks.ipynb)\n",
    "# - ../data/processed/df_xray_processed_normed_enc_train.cvs        (this is output from train_test_split.ipynb)\n",
    "# - ../data/processed/df_xray_processed_normed_enc_test.csv         (this is output from train_test_split.ipynb)\n",
    "\n",
    "\n",
    "\n",
    "# output:\n",
    "# -  augmented images in folder: data\\processed\\augmented_without_masks_resized\n",
    "# - ../data/processed/df_xray_train_norm_plus_augmented_without_masks_resized.csv\n",
    "# - ../data/processed/df_xray_test_norm_without_masks_resized.csv\n",
    "# - train_data_resized_without_masks.npz\n",
    "# - test_data_resized_without_masks.npz\n",
    "\n",
    "\n",
    "# Augmented data is created in the folder data\\processed\\augmented_without_masks_resized for the minority classes: [\"COVID\", \"Viral Pneumonia\", \"Lung_Opacity\"].\n",
    "# Additionally a csv-file 'df_xray_train_norm_plus_augmented_without_masks_resized.csv' is created in which all the images belonging to the training set (incl. augmented)\n",
    "# are listed with labels and encoded labels.\n",
    "# Additionally a the train data and labels are saved as flattened numpy arrays: train_data_resized_without_masks.npz\n",
    "# The associated test data set is produced aswell and saved as a flattened numpy array: test_data_resized_without_masks.npz\n",
    "\n",
    "\n",
    "%run data_augmentation_without_masks.ipynb\n",
    "\n",
    "# P.S.: I could not reuse data_augmentation.ipynb because the input folders have different structures\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "631841ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yvonne\\Documents\\DataScientist_2025_local\\project_code\\notebooks\n",
      "Loading images from: c:\\Users\\Yvonne\\Documents\\DataScientist_2025_local\\project_code\\data\\processed\\df_xray_train_norm_plus_augmented.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading and processing train images: 100%|██████████| 35059/35059 [00:24<00:00, 1417.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (35059, 400)\n",
      "y_train shape: (35059,)\n",
      "Resized and flattened train images have been saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading and processing test images: 100%|██████████| 4233/4233 [00:03<00:00, 1124.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (4233, 400)\n",
      "y_test shape: (4233,)\n",
      "Resized and flattened test images have been saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 5c) resize images which are output from step 5a) and resizes them\n",
    "\n",
    "# input: \n",
    "# - \"...\\data\\processed\\df_xray_train_norm_plus_augmented.csv\"\n",
    "\n",
    "# output is: \n",
    "#  - \"...\\data\\processed\\train_data_resized_with_masks.npz\"\n",
    "# -  \"...\\data\\processed\\test_data_resized_with_masks.npz\"\n",
    "\n",
    "%run Resize_norm_images_with_masks.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f81793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Feature Extraction for Train and Test Sets\n",
    "# ---------------------------------------------------\n",
    "# - Extract deep features (ResNet, VGG16) and traditional features (HOG, GLCM)\n",
    "# - Convert processed X-ray images into feature vectors\n",
    "# - Save features and labels as .npy files for both train and test sets\n",
    "\n",
    "# Input for this step:\n",
    "# - Train CSV: ../data/processed/df_xray_train_norm_plus_augmented.csv         # (from Step 5)\n",
    "# - Test CSV : ../data/processed/df_xray_processed_normed_enc_test.csv         # (from Step 4)\n",
    "\n",
    "# Output of this step:\n",
    "# - labels_train.npy\n",
    "# - labels_test.npy\n",
    "# - ResNet_HOG.npy\n",
    "# - ResNet_HOG_test.npy\n",
    "# - ResNet_HOG_GLCM.npy\n",
    "# - ResNet_HOG_GLCM_test.npy\n",
    "# - combined_hog_vgg.npy\n",
    "# - combined_hog_vgg_test.npy\n",
    "\n",
    "# Note: These features are saved and also available in the linked Google Drive folders:\n",
    "# - Train Features: https://drive.google.com/drive/folders/1tEVfGVhBFkIAV_ZpImKqU5HtjrJPQtgr?usp=drive_link\n",
    "# - Test Features : https://drive.google.com/drive/folders/1dnpbcx8M8pjGWIvnXDOq7TqO1O8CKQ4m?usp=drive_link\n",
    "# - Label Files   : \n",
    "#    - labels_train.npy: https://drive.google.com/file/d/1IcdiNVn529CIGXCPdv7PYEQcbXQScGWy/view?usp=drive_link\n",
    "#    - labels_test.npy : https://drive.google.com/file/d/12adEjCtiv-OJfmlcmIckPN9m4qAzXELz/view?usp=drive_link\n",
    "\n",
    "# Notebooks for this step:\n",
    "%run feature_extraction.ipynb\n",
    "%run feature_extraction_test.ipynb\n",
    "\n",
    "# Load results (used in model training later):\n",
    "X_train = np.load(\"ResNet_HOG.npy\")\n",
    "y_train = np.load(\"labels_train.npy\")\n",
    "X_test  = np.load(\"ResNet_HOG_test.npy\")\n",
    "y_test  = np.load(\"labels_test.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833f07c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6. ML Modeling + Hyperparameter Tuning\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC()\n",
    "\n",
    "# GridSearch\n",
    "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# RandomSearch\n",
    "param_dist = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "random_search = RandomizedSearchCV(model, param_dist, cv=5, n_iter=6, scoring='accuracy')\n",
    "\n",
    "# BayesSearch\n",
    "search_spaces = {'C': (0.1, 50.0), 'kernel': ['linear', 'rbf']}\n",
    "bayes_search = BayesSearchCV(model, search_spaces, n_iter=10, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit\n",
    "# grid_search.fit(X_train_bal, y_train_bal)\n",
    "# random_search.fit(X_train_bal, y_train_bal)\n",
    "# bayes_search.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "# 7. Evaluate Models\n",
    "# print(grid_search.best_params_)\n",
    "# print(random_search.best_params_)\n",
    "# print(bayes_search.best_params_)\n",
    "# Predict, Confusion Matrix, Accuracy\n",
    "\n",
    "# 8. Deep Learning Path (Instead of ML)\n",
    "# - Use data augmentation on minority classes\n",
    "# - Fine-tune pretrained CNN (EfficientNet, ResNet, etc.)\n",
    "# - Evaluate on test set\n",
    "# - Compare results to ML\n",
    "\n",
    "# 9. Save Best Model\n",
    "# from joblib import dump\n",
    "# dump(grid_search.best_estimator_, 'best_model.joblib')\n",
    "\n",
    "# OR (DL)\n",
    "# model.save(\"best_dl_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0aac214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (1076, 16384)\n",
      "y_test shape: (1076,)\n",
      "Resized and flattened test images have been saved!\n",
      "X_train shape: (4000, 16384)\n",
      "y_train shape: (4000,)\n",
      "Resized and flattened train images have been saved!\n"
     ]
    }
   ],
   "source": [
    "### Optional:\n",
    "# Create a small dataset which with only non-augmented images\n",
    "# in order to have balanced classes the maximum number of images per class is 1345 (which is the number of images in the Viral Pneumonia class)\n",
    "\n",
    "# input: \n",
    "# ../data/processed/df_xray_processed_normed_enc_test.cvs   (is created by train_test_split.ipynb)\n",
    "# ../data/processed/df_xray_processed_normed_enc_train.cvs (is created by train_test_split.ipynb)\n",
    "\n",
    "%run create_small_dataset_nonaugmented.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7badfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
